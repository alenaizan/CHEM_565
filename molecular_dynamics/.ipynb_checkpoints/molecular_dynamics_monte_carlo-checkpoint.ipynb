{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbe4329",
   "metadata": {},
   "source": [
    "# Molecular Dynamics and Monte Carlo\n",
    "For small or rigid molecules which do not have a lot of structural flexibility, geometry optimization is typically carried out in order to determine the minimum energy structure, and then the properties of the molecule are computed at the minimum or minima. However, for larger molecules or for a big collection of small molecules (e.g., solvent), there will be numerous low energy structures that are accessible under typical conditions (e.g. ambient temperature). To get a more appropriate description of such systems, we need to explore their various possible configurations and obtain some *average* picture. Monte Carlo (MC) and molecular dynamics (MD) methods enable the exploration of the various possible configurations of the system.\n",
    "\n",
    "## Overview of Monte Carlo and Molecular Dynamics Methods\n",
    "MC and MD methods are powerful techniques for sampling the possible configurations of the system. The state of the system is completely specified by the positions and momenta of all the particles. The *phase space* is the space in which all possible states of the system (positions and momenta) are represented. \n",
    "\n",
    "In MC methods, we start from some initial structure of the system. Then, we *randomly* perturb the coordinates of a randomly chosen particle. In the popular *Metropolis* approach, we always accept the move if the energy of the system decreases. If the energy increases, we generate a random number between 0 and 1 and accept the move if $e^{-\\Delta E/kT}$ is larger than the random number. This acceptance and rejection criteria allows overcoming potential energy barriers and the escape from local minima. Typically, the perturbation should be small so as to have a reasonable acceptance ration. However, this means that only a small portion of the configurational space can be explored. The Metropolis algorithm depends on the temperature and therefore MC methods are normally perform at constant number of particle, volume, and temperature (NVT) or the canonical ensemble. \n",
    "\n",
    "There are several advantages of MC methods. First, the perturbations can be performed in Cartersian or internal coordinates (i.e., bond lengths, angles, dihedrals). Second, only energy evaluation is required and calculating derivatives of the energy is not needed. Third, because only one (or a few) particle is perturbed at each step, only the energy change associated with the perturbation needs to be calculated. Finally, it is easy to constrain certain degrees of freedom. One disadvantage of MC methods is its indepdence on time and velocities, and thus MC methods cannot explore time-depedent phenomena or properties that depend on the momentum (e.g., diffusion).\n",
    "\n",
    "MD methods explore the evolution of the system over time by integrating Newton's second law ($\\textbf{F}=m \\textbf{a}$). A small time step (typically $\\sim 1$ fs) is usually used and therefore $10^6$ steps only explore the evolution of the system in 1 ns. Some physical processes, such as protein folding, occur at long time scales, and therefore short MD simulations only sample the region of the phase space close to the initial structure. Because the forces determine the *trajectory* of the particles, standard MD simulations cannot easily climb potential energy barriers because they will experience a force in the opposite direction. MD simulations are in principle deterministic, but very small numerical differences ($\\sim 10^{-8}$) can rapidly cause the irreproducibility of MD trajectories. Because MD simulations have velocity and time dependence, they can explore time-dependent properties like transport phenomena. Unlike MC methods, MD simulations require the calculation of both the energy and its derivative. Furthermore, all the particles move each step, unlike MC methods. MD simulations are performed in Cartesian coordinates. Imposing constraints on the degrees of freedom is more challenging than in MC methods. For MD methods, the natural ensemble is the microcanonical ensemble (NVE; constant number of particles, volume, and energy), though other ensembles can also be generated. \n",
    "\n",
    "The differences between MC and MD methods are summarized below:\n",
    "\n",
    "<img src=\"mc_vs_md.png\" alt=\"drawing\" width=\"600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af318d7a",
   "metadata": {},
   "source": [
    "## Monte Carlo\n",
    "The basic idea of Monte Carlo methods is the random sampling of the phase space of molecules. As summarized above, a perurbation to the molecular structure is introduced either in Cartesian or internal coordinates. The move is always accepted if it lowers the energy. If it raises the energy, the move is accepted if $e^{-\\Delta E/kT}$ is larger than a randomly generated number between 0 and 1.\n",
    "\n",
    "### Random Number Generation\n",
    "Typically, numbers are generated by a pseduo-random number generator, where the numbers are not truly random. The key point for random number generators is that they generate a very long sequence of apparently uncorrelated numbers. However, after a long sequence, the numbers will be repeated exactly. Usually, the sequence of (random) numbers can be fixed by using a given initial value (called *seed*). However, depending on the implementation, it may not be possible to generate the same sequence of numbers if different compilers or different computer architectures are used. Using an initial seed can be useful for debugging the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1882f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random numbers 1: [0.65776693 0.71067443 0.75045599 0.57845144 0.56812496 0.62737347]\n",
      "Random numbers 2: [0.31369869 0.1535036  0.99935995 0.54016243 0.49005929 0.87022411]\n",
      "Random numbers 1 (fixed seed): [0.5488135  0.71518937 0.60276338 0.54488318 0.4236548  0.64589411]\n",
      "Random numbers 2 (same seed): [0.5488135  0.71518937 0.60276338 0.54488318 0.4236548  0.64589411]\n"
     ]
    }
   ],
   "source": [
    "# Numpy has different functionalities for random number generation\n",
    "import numpy as np\n",
    "\n",
    "# Generate an array of 6 random numbers\n",
    "print(\"Random numbers 1:\", np.random.rand(6))\n",
    "\n",
    "# Generate a second array of 6 random numbers; They will be different\n",
    "print(\"Random numbers 2:\", np.random.rand(6))\n",
    "\n",
    "# Now fix the seed using an integer value of zero\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate an array of 6 random numbers\n",
    "print(\"Random numbers 1 (fixed seed):\", np.random.rand(6))\n",
    "\n",
    "# Now again set the seed value\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate a second array of 6 random numbers; The numbers will be the same\n",
    "print(\"Random numbers 2 (same seed):\", np.random.rand(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd3a53",
   "metadata": {},
   "source": [
    "### Size of Perturbation Step\n",
    "The size of the perturbation is an important parameter. A small size will lead to higher acceptance ratio, but it will lead to a slow exploration of the phase space. A large step will lead to a smaller acceptance ratio, and a sampling that consists of wide jumps.\n",
    "\n",
    "### Nonphysical Moves\n",
    "Because the perturbations are random, they can make physically unrealistic moves. This can be an advantage because this allows the Monte Carlo procedure to tunnel through high energy barrier. However, sometimes this can be a problem. For example, the chirality of the molecule may be inverted in a random move but this might be an undesired change.\n",
    "\n",
    "### Correlated Motions\n",
    "Because only one (or a few) particles are moved in each step, it is difficult to explore correlated changes in the configuration. For example, the dihedral angles in the protein backbone are correlated, and only certain combinations of values give an acceptable structure. However, a small perturbation in only one dihedral angle may raise the energy substantially because of atom clashes, and thus such a move will likely be rejected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11640ad6",
   "metadata": {},
   "source": [
    "## Molecular Dynamics\n",
    "In molecular dynamics simulations, we use Newton's second law $\\textbf{F} = m \\textbf{a}$ to describe the evolution of the system over time. In the differential form, Newton's second law is given by:\n",
    "\\begin{align}\n",
    "    -\\frac{dV}{d\\textbf{r}} = m \\frac{d^2 \\textbf{r}}{dt^2}\n",
    "\\end{align}\n",
    "where $V$ is the potential energy at position $\\textbf{r}$. Given an initial configuration $\\textbf{r}_i$, we can determine the configuration at any other time by integrating Newton's equation. Except for a few simple cases, the integration cannot be performed analytically and therfore numerical integration is needed.\n",
    "\n",
    "### Numerical Integrators Example: The Verlet Algorithm\n",
    "The Verlet algorithm is a common approach for integrating Newton's equation. Given an initial configuration $\\textbf{r}_i$, the position after a small time step $\\Delta t$ is given by the Taylor expansion:\n",
    "\\begin{align}\n",
    "    \\textbf{r}_{i+1} &= \\textbf{r}_i + \\frac{\\partial \\textbf{r}}{\\partial t} (\\Delta t) + \n",
    "                              + \\frac{1}{2} \\frac{\\partial^2 \\textbf{r}}{\\partial t^2} (\\Delta t)^2 +\n",
    "                              + \\frac{1}{6} \\frac{\\partial^3 \\textbf{r}}{\\partial t^3} (\\Delta t)^3 + \\cdots\\\\\n",
    "    \\textbf{r}_{i+1} &= \\textbf{r}_i + \\textbf{v}_i (\\Delta t) +  \\frac{1}{2} \\textbf{a}_i (\\Delta t)^2 +\n",
    "                        \\frac{1}{6} \\textbf{b}_i (\\Delta t)^3 + \\cdots\n",
    "\\end{align}\n",
    "where $\\textbf{v}_i, \\textbf{a}_i, \\textbf{b}_i$ are the velocity, acceleration, and hyper-acceleration at time $t_i$.\n",
    "\n",
    "Similarly, the position at time step $\\Delta t$ earlier is given by substituting $\\Delta t$ with $-\\Delta t$:\n",
    "\\begin{align}\n",
    "    \\textbf{r}_{i-1} &= \\textbf{r}_i - \\textbf{v}_i (\\Delta t) +  \\frac{1}{2} \\textbf{a}_i (\\Delta t)^2 -\n",
    "                        \\frac{1}{6} \\textbf{b}_i (\\Delta t)^3 + \\cdots  \n",
    "\\end{align}\n",
    "\n",
    "Addition of the two above equations gives a formula for calculating the position at time $\\Delta t$ given the two previous positions and the current acceleration:\n",
    "\\begin{align}\n",
    "    \\textbf{r}_{i+1} &= (2 \\textbf{r}_i - \\textbf{r}_{i-1}) + \\textbf{a}_i (\\Delta t)^2 + \\cdots \\\\\n",
    "    \\textbf{a}_i &= \\frac{\\textbf{F}_i}{m_i} = -\\frac{1}{m_i} \\frac{dV}{d \\textbf{r}_i}.\n",
    "\\end{align}\n",
    "\n",
    "This is the Verlet algorithm. The term involving $\\textbf{b}$ disappears and therefore this expression is correct to third order in $\\Delta t$. At the initial point, the previous position is estimated from the initial position and the initial velocity:\n",
    "\\begin{align}\n",
    "    \\textbf{r}_{-1} = \\textbf{r}_0 - \\textbf{v}_0 \\Delta t\n",
    "\\end{align}\n",
    "\n",
    "As the time step $\\Delta t$ decreases, the approximation increases in accuracy. However, a small time step requires many simulation steps to reach a given total simulation time.\n",
    "\n",
    "#### Integration Time Step\n",
    "The fastest process in the system determines the maximum time step that can be taken, with the appropriate time step typically being an order of magnitude slower. Molecular rotations and vibrations occur with frequencies in the range of $10^{11}-10^{14}$ s$^{-1}$. Thus, typically a 1 fs ($10^{-15}$) time step is usually chosen. A million time step therefore simulates the system for only 1 ns, which may not be enough to explore some chemical systems.\n",
    "\n",
    "The fastest process is typically bond stretching that involves hydrogen atoms. These degrees of freedom, however, often have little influence on some chemical properties. Thus, bonds involving hydrogen atoms are often frozen. This allows a time step of 2 fs to be used. Other techniques can also be used to increase the time step more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30532c90",
   "metadata": {},
   "source": [
    "### Non-natural Ensembles\n",
    "The natural ensemble for solving Newton's equation is the microcanonical ensemble (NVE). In this ensemble, the pressure and temperature fluctuate. The total energy is the sum of the kinetic and potential energies:\n",
    "\\begin{align}\n",
    "    E_{\\rm tot} = \\sum_{i=1}^N \\frac{1}{2} m_i \\textbf{v}_i^2 + V(\\textbf{r})\n",
    "\\end{align}\n",
    "\n",
    "The average kinetic energy for a large number of particle $N$ is related to the temperature by\n",
    "\\begin{align}\n",
    "    \\langle E_{\\rm kin} \\rangle = \\frac{3}{2} N k_{\\rm B} T\n",
    "\\end{align}\n",
    "\n",
    "The microcanonical ensemble is not convenient because it is difficult to devise experimental conditions where the NVE variables are constant. Experimentally, it is easier to fix the temperature and pressure. Ensembles with fixed termperature/pressure can also be generated for MD simulations\n",
    "\n",
    "#### The Canonical Ensemble (NVT)\n",
    "In the canonical ensemble, the temperature is fixed by coupling the system to a large heat reservior. Because the temperature is related to the kinetic energy and the velocity of the particles, the temperature of the simulation can be controlled by scaling the velocity of all particles. Scaling the velocity at each time step introduces unwanted changes in the dynamics. Instead, usually a *thermostat* or a heat bath is used to add or remove energy from the system at suitable time intervals. A commonly used thermostat is the Nose-Hoover thermostat.\n",
    "\n",
    "#### The Isothermal-Isobaric Ensemble (NPT)\n",
    "In addition to controlling the temperature, the pressure can also be controlled to produce the isothermal-isobaric ensemble (NPT). Again, a *barostat* or a pressure bath can be used to control the pressure. Barostats work by scaling the volume of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbaf1cc",
   "metadata": {},
   "source": [
    "### Periodic Boundary Conditions\n",
    "Molecular dynamics simulation are performed for relatively small systems. If the particles are not constrained somehow, some molecules may potentially boil off into space. Furthermore, for small systems, surface effects can become important. To address these limitations, *periodic boundary conditions* are usually used.\n",
    "\n",
    "When periodic boundary conditions are employed in the simulation, a box of the system become surrounded by other fictitious simulation boxes as illustrated in the image below:\n",
    "\n",
    "<img src=\"periodic_boundary_conditions.png\" alt=\"drawing\" width=\"200px\"/>\n",
    "\n",
    "If a particle escape from one side, then it re-appears in the opposite side because the system becomes periodic. A cubic box is often used but other types of boxes are also possible. Because electrostatic interactions is a long-range force in the system, it needs special treatment for periodic systems. Electrostatic interactions for periodic systems are usually calculated using the Ewald sum methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00026b9",
   "metadata": {},
   "source": [
    "### Extracting Information from Simulations\n",
    "The main output of an MD simulation is the MD trajectory, which is the sequence of positions (and possibly momenta) of the particles at each time step. Furthermore, other properties, such as thermodynamic quantities, can be extracted from the simulations. We generally calculated *average* quantities from MD trajectories. A single MD snapshot does not represent a statistically meaningful observation.\n",
    "\n",
    "#### The Ergodic Hypothesis\n",
    "In statistical mechanics, we are concerned with *average* properties. A single particle (or a few particles) explores the phase space over time, and thus we can define an *average over time* as:\n",
    "\\begin{align}\n",
    "    \\langle X \\rangle = \\lim_{\\tau \\to \\infty} \\frac{1}{\\tau} \\int_0^\\tau X(t) dt\n",
    "\\end{align}\n",
    "Alternatively, for a large number of identical particles, each particle will occupy a certain region of the phase space at any given time. Thus, we can also calculate the *ensemble average* as:\n",
    "\\begin{align}\n",
    "    \\langle X \\rangle = \\lim_{M \\to \\infty} \\frac{1}{M} \\sum_{i=1}^M X_i\n",
    "\\end{align}\n",
    "\n",
    "The *ergodic hypothesis* asserts that these two averages are equal.\n",
    "\n",
    "#### Equilibration and Production Stages\n",
    "To perform an MD simulation, an initial structure is required. This is often an X-ray structure of the system if available or some guess structure generated by a modeling program. This initial structure is usually high in energy. To prevent the presence of strong forces in the beginning which can destabilize the simulation, energy minimization to a nearby local minima is performed before running the simulation. Still, the structure in the beginning of the simulation can still be far from equilibrium.\n",
    "\n",
    "The above equations for the averages assume that the system is at equilibrium. Therefore, an MD trajectory is usually divided to two stages: *equilibration* and *production*. The equilibration stage is supposed to bring the system to the equilibrium structure. Data from the equilibration stage are not used to calculate the averages. Only data from the production stage are used.\n",
    "\n",
    "There is no strict way to partition the trajectory to equilibration and production stages. Often, some initial portion of the trajectory is discarded as equilibration. Discarding too little can bias the results towards the initial structure while discarding too much can increase the statistical error in the average data. Generally, thermodynamic properties, such as the energy and the temperature, can be monitored to establish whether they reached stable values with limited fluctuations.\n",
    "\n",
    "#### Uncorrelated Samples\n",
    "The above averages assume that the samples are *uncorrelated*. In MD simulations, snapshots should be saved at suitable intervals of time where the property of interest is uncorrelated. Saving too many snapshots can take a lot of storage space while adding little statistical significance. Different ways can be used to estimate the correlation times for different properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e84627",
   "metadata": {},
   "source": [
    "## Useful Resources\n",
    "\n",
    "- Cramer, C. J. *Essentials of Computational Chemistry: Theories and Models*, 2nd ed.; John Wiley & Sons: Chichester, England, 2004. (Chapters 3, 12, and 13)\n",
    "- Jensen, F. *Introduction to Computational Chemistry*, 3rd ed.; John Wiley & Sons: Nashville, TN, 2017. (Chapter 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b57095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
